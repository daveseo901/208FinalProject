{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b65f3a3-20bc-4cc4-ba2b-101ecfa9bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4018b3-b1c6-4b7a-8f7e-283b14c8a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address(address):\n",
    "    try:\n",
    "        seps = re.compile(r'( St)|( Rd)|( Ave)|( Ct)|( Blvd)|( Dr)|( Ln)|( Pl)|( Sq)', flags = re.IGNORECASE)\n",
    "        clean_addr = list(filter(None, re.split(seps, address)))\n",
    "        clean_addr = clean_addr[0] + clean_addr[1]\n",
    "        geolocator = Nominatim(user_agent=\"208final\")\n",
    "        location = geolocator.geocode(clean_addr)\n",
    "        return (location.latitude, location.longitude)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cd3c54a-4a1b-4ff1-b274-8ccefcb2ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"Carmel\", \"Diplo\", \"Federal\", \"Firstclass\", \"Highclass\", \"Prestige\"]\n",
    "utf = [\"Carmel\", \"Diplo\", \"Firstclass\", \"Highclass\", \"Prestige\"]\n",
    "cols = {}\n",
    "cols['Carmel'] = ['Date', 'Time', 'PU_Adress']\n",
    "cols['Diplo'] = ['Date', 'Time', 'PU_Address']\n",
    "cols['Federal'] = ['Date', 'Time', 'PU_Address']\n",
    "cols['Firstclass'] = ['DATE', 'TIME', 'PICK UP ADDRESS']\n",
    "cols['Highclass'] = ['DATE', 'TIME', 'PU_Address']\n",
    "cols['Prestige'] = ['DATE', 'TIME', 'PICK UP ADDRESS']\n",
    "\n",
    "def get_df(carrier):\n",
    "    filename = \"\"\n",
    "    if carrier in utf:\n",
    "        filename = \"raw_data/\" + carrier + \"_utf.csv\"\n",
    "    else:    \n",
    "        filename = \"raw_data/\" + carrier + \".csv\"\n",
    "    print(filename)\n",
    "    n = sum(1 for line in open(filename)) - 1\n",
    "    s = int(n / 1000)\n",
    "    print(s)\n",
    "    skip = sorted(random.sample(range(1, n+1), n-s))\n",
    "    df = pd.read_csv(filename, skiprows=skip)\n",
    "    df = df.rename(columns={cols[carrier][0]: \"date\", cols[carrier][1]: \"time\", cols[carrier][2]: \"location\"})[[\"date\", \"time\", \"location\"]]\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"]).dt.time\n",
    "    df[\"location\"] = [clean_address(row[\"location\"]) for index, row in tqdm(df.iterrows())]\n",
    "    df.dropna(subset=[\"location\"], inplace = True)\n",
    "    df[\"carrier\"] = carrier.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998380d5-39f9-457e-b451-625ba86e2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [00:43,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "filename = \"raw_data/American.csv\"\n",
    "n = sum(1 for line in open(filename)) - 1\n",
    "s = int(n / 1000)\n",
    "print(s)\n",
    "skip = sorted(random.sample(range(1, n+1), n-s))\n",
    "df = pd.read_csv(filename, skiprows=skip)\n",
    "df = df.rename(columns={'DATE': \"date\", 'TIME': \"time\", 'PICK UP ADDRESS': \"location\"})[[\"date\", \"time\", \"location\"]]\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"]).dt.time\n",
    "geolocator = Nominatim(user_agent=\"208final\")\n",
    "df[\"location\"] = [clean_address(row[\"location\"]) for index, row in tqdm(df.iterrows())]\n",
    "df.dropna(subset=[\"location\"], inplace = True)\n",
    "df[\"carrier\"] = \"american\"\n",
    "big_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29157561-eb81-4d58-b00e-ad88a0be7e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date      time                                 location   carrier\n",
      "1  2014-07-04  17:15:00                 (40.8161391, -73.904608)  american\n",
      "2  2014-07-06  12:33:00                (40.8192885, -73.8997237)  american\n",
      "3  2014-07-07  04:45:00                (40.8152388, -73.9160874)  american\n",
      "4  2014-07-09  11:54:00  (40.81610072727273, -73.90402954545455)  american\n",
      "5  2014-07-09  19:01:00                 (40.815306, -73.8987435)  american\n",
      "..        ...       ...                                      ...       ...\n",
      "84 2014-09-27  01:54:00         (40.817868000000004, -73.853939)  american\n",
      "86 2014-09-27  17:29:00                (40.8111478, -73.9168744)  american\n",
      "87 2014-09-27  21:30:00        (40.82492209375, -73.90495953125)  american\n",
      "89 2014-09-28  05:39:00                (40.8134483, -73.9153797)  american\n",
      "90 2014-09-30  07:22:00                (40.8120839, -73.9041639)  american\n",
      "\n",
      "[81 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(big_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dbc6297-fa78-4967-8546-c0a603b4c2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/Carmel_utf.csv\n",
      "256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "256it [05:11,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/Diplo_utf.csv\n",
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [00:49,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/Federal.csv\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/Firstclass_utf.csv\n",
      "166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [02:30,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/Highclass_utf.csv\n",
      "151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [01:22,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/Prestige_utf.csv\n",
      "320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [02:34,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    big_df = big_df.append(get_df(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f563ab9-0fcb-458d-b1a6-e452bd06d5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date      time                                  location   carrier\n",
      "1   2014-07-04  17:15:00                  (40.8161391, -73.904608)  american\n",
      "2   2014-07-06  12:33:00                 (40.8192885, -73.8997237)  american\n",
      "3   2014-07-07  04:45:00                 (40.8152388, -73.9160874)  american\n",
      "4   2014-07-09  11:54:00   (40.81610072727273, -73.90402954545455)  american\n",
      "5   2014-07-09  19:01:00                  (40.815306, -73.8987435)  american\n",
      "..         ...       ...                                       ...       ...\n",
      "312 2014-09-28  07:18:00   (40.87678204081632, -73.85872673469387)  prestige\n",
      "313 2014-09-28  09:13:00               (40.8768236875, -73.853798)  prestige\n",
      "314 2014-09-29  08:48:00                 (40.8350854, -73.9118444)  prestige\n",
      "317 2014-09-29  17:00:00  (40.859985040816326, -73.84296128571428)  prestige\n",
      "319 2014-09-30  23:39:00  (40.848002300000005, -73.84378242145698)  prestige\n",
      "\n",
      "[743 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(big_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22900418-7e65-4f59-9dc0-97b85d790b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_csv(\"small_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7141df46-efa2-475a-81ba-036d82ff54fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_df(carrier):  \n",
    "    filename = \"raw_data/\" + carrier + \".csv\"\n",
    "    print(filename)\n",
    "    n = sum(1 for line in open(filename)) - 1\n",
    "    s = int(n / 1000)\n",
    "    print(s)\n",
    "    skip = sorted(random.sample(range(1, n+1), n-s))\n",
    "    df = pd.read_csv(filename, skiprows=skip)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"Date/Time\"]).dt.date\n",
    "    df[\"time\"] = pd.to_datetime(df[\"Date/Time\"]).dt.time\n",
    "    df[\"location\"] = list(zip(df.Lat, df.Lon))\n",
    "    df[\"carrier\"] = \"uber\"\n",
    "    df = df[[\"date\", \"time\", \"location\", \"carrier\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93957ee7-9084-4ff3-a310-8bf1b3da1794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/Uber_Jul.csv\n",
      "796\n",
      "raw_data/Uber_Aug.csv\n",
      "829\n",
      "raw_data/Uber_Sep.csv\n",
      "1028\n"
     ]
    }
   ],
   "source": [
    "big_df = pd.DataFrame()\n",
    "for carrier in [\"Uber_Jul\", \"Uber_Aug\", \"Uber_Sep\"]:\n",
    "    big_df = big_df.append(get_uber_df(carrier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8182739-5d9c-4bf0-bd82-1b873eef4e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date      time                       location carrier\n",
      "0     2014-07-01  16:20:00            (40.7189, -74.0026)    uber\n",
      "1     2014-07-02  18:20:00            (40.7713, -73.9836)    uber\n",
      "2     2014-07-04  11:52:00            (40.7739, -73.8724)    uber\n",
      "3     2014-07-04  18:17:00            (40.7527, -73.9675)    uber\n",
      "4     2014-07-05  12:31:00            (40.7726, -73.9812)    uber\n",
      "...          ...       ...                            ...     ...\n",
      "1023  2014-09-30  08:28:00            (40.7843, -73.9585)    uber\n",
      "1024  2014-09-30  13:01:00            (40.7287, -73.9548)    uber\n",
      "1025  2014-09-30  15:00:00  (40.7764, -73.94800000000001)    uber\n",
      "1026  2014-09-30  16:12:00            (40.7758, -73.9507)    uber\n",
      "1027  2014-09-30  19:30:00            (40.7587, -73.9775)    uber\n",
      "\n",
      "[2653 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(big_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4134d2c7-42f6-4ab1-9977-05385fd3230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.read_csv(\"small_data.csv\").append(big_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f3f3eab-f620-49df-bdf9-71a7e01dda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_csv(\"small_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151db51-cf74-4edd-bbea-5835d9d64c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
